---
title: "Final Project EDA and Data Evaluation"
author: "Your Name"
date: "November 2024"
output:
  pdf_document: default
  html_document: default
---

### Question 3: Evaluating Data Quality

This question encourages you to begin the exploratory data analysis (EDA) for your final project. By addressing potential data quality issues early, you can identify and rectify problems promptly. For each important variable in your dataset, assess its quality by creating a table that includes the following:

-   **Continuous variables**:
    -   The number of non-missing observations.
    -   The number of missing observations.
    -   Measures of central tendency (e.g., mean, median).
    -   Measures of variability (e.g., standard deviation, interquartile range [IQR]).
-   **Categorical variables**:
    -   The levels of the variable.
    -   For each level:
        -   The number of non-missing observations.
        -   The number of missing observations.

### Answer: Comparing Predictive Performance of Betting Markets and Polls


```{r}
install.packages("readr")
install.packages("dplyr")

```

```{r}
# Load necessary libraries
library(readr)
library(dplyr)
```

Our project aims to compare the predictive accuracy of betting markets and polls in forecasting the outcome of the 2024 U.S. presidential election by state. We use the following datasets:

1.  **Betting Market Data**
    -   Sourced from a Kaggle dataset, this dataset scrapes Polymarket's 2024 election results by state and consolidates them into a CSV file ([source](https://www.kaggle.com/datasets/pbizil/polymarket-2024-us-election-state-data)).
2.  **Poll Data**
    -   Sourced from FiveThirtyEight, this dataset provides polling averages and raw data from the 2024 U.S. presidential election ([source](https://projects.fivethirtyeight.com/polls/president-general/2024/national/)).
3.  **Actual Election Results**
    -   Sourced from CBS News, this dataset reports the official 2024 presidential election results ([source](https://www.cbsnews.com/elections/2024/president/)).

#### Exploratory Data Analysis (EDA)

**Dataset 1: Betting Market Data**

The dataset provides separate files for each state, containing the probability of a Republican win under the column "Donald Trump" and a Democratic win under "Kamala Harris." These probabilities are based on the amount bet on Polymarket for each candidate. Data was aggregated by month, resulting in a final dataset of state-level probabilities for Republican and Democratic wins from April 17, 2024, to November 4, 2024. Non-missing and missing observations were quantified for each probability column. Mean probabilities and standard deviations for Republican and Democratic wins nationwide were calculated.

```{r}

# Define the directory containing the files
file_path <- "data/betting_data/polymarket/csv_month/"

# Get a list of all CSV files in the directory
file_list <- list.files(path = file_path, pattern = "*.csv", full.names = TRUE)

# Initialize data frames to store results
final_data <- data.frame()
missing_data_summary <- data.frame()

# Loop through each file to process data
for (file in file_list) {
  # Read the CSV file
  state_data <- read_csv(file)
  
  # Extract the state abbreviation from the file name
  state_abbrev <- tools::file_path_sans_ext(basename(file)) %>% 
    stringr::str_extract("^[A-Z]{2}")
  
  # Calculate averages for Donald Trump and Kamala Harris
  avg_trump <- mean(state_data$`Donald Trump`, na.rm = TRUE)
  avg_harris <- mean(state_data$`Kamala Harris`, na.rm = TRUE)
  
  # Count missing and non-missing observations for each candidate
  non_missing_trump <- sum(!is.na(state_data$`Donald Trump`))
  missing_trump <- sum(is.na(state_data$`Donald Trump`))
  non_missing_harris <- sum(!is.na(state_data$`Kamala Harris`))
  missing_harris <- sum(is.na(state_data$`Kamala Harris`))
  
  # Append missing data summary for this state
  missing_data_summary <- bind_rows(
    missing_data_summary,
    data.frame(
      state = state_abbrev,
      candidate = "Donald Trump",
      non_missing = non_missing_trump,
      missing = missing_trump
    ),
    data.frame(
      state = state_abbrev,
      candidate = "Kamala Harris",
      non_missing = non_missing_harris,
      missing = missing_harris
    )
  )
  
  # Create a new data structure for average percentages
  state_results <- data.frame(
    candidate = c("Donald Trump", "Kamala Harris"),
    percentage = c(avg_trump, avg_harris),
    state = c(state_abbrev, state_abbrev)
  )
  
  # Append to the final data frame
  final_data <- bind_rows(final_data, state_results)
}

# Calculate nationwide statistics
nationwide_stats <- final_data %>%
  group_by(candidate) %>%
  summarise(
    nationwide_mean = mean(percentage, na.rm = TRUE),
    nationwide_sd = sd(percentage, na.rm = TRUE),
    total_non_missing = sum(!is.na(percentage)),
    total_missing = sum(is.na(percentage))
  )

# View the final summaries
print("Missing Data Summary:")
print(missing_data_summary)

print("Nationwide Statistics:")
print(nationwide_stats)

```

**Dataset 2: Poll Data**

The dataset contains average polling data by candidate, date, and their adjusted percentage of being favored. We started out by exploring how many missing and non-missing data point there were for Harris and Trump. We then aggregated data over time, such that we are left with poll percentages for Harris/Trump per state. We take the mean to find the average poll percentage for Harris and Trump nationwide. We then take the standard deviation.

```{r}
polling_data <- read.csv("data/polls_survey_data/538_data/polls_average_2024.csv")
library(dplyr)
library(tidyverse)

```

```{r}

#isolate 2024 polling data (there are many rwos from 2020 in here with no values)
polling2024 <- polling_data %>%
  filter(cycle == 2024) %>%
  #take out the pct_trend_adjusted column (it's NA everywhere)
  select(- pct_trend_adjusted)

```

```{r}
#categorical variables - checking for missing data

```

**Dataset 3: Election Results**

The dataset contains the number of votes for Harris and Trump, separated by state. We find the percentage who voted for Harris and Trump, the amount of missing and non-missing data, and the mean and variance. 

```{r}

# Load the dataset
actual_results <- read_csv("data/actual_results_data/state_results_2024.csv")

# Add percentage columns for Harris and Trump
actual_results <- actual_results %>%
  mutate(
    percent_harris = (Harris_Votes / (Harris_Votes + Trump_Votes)) * 100,
    percent_trump = (Trump_Votes / (Harris_Votes + Trump_Votes)) * 100
  )

# Calculate the number of missing and non-missing observations for each column
missing_summary <- actual_results %>%
  summarise(
    missing_harris = sum(is.na(Harris_Votes)),
    non_missing_harris = sum(!is.na(Harris_Votes)),
    missing_trump = sum(is.na(Trump_Votes)),
    non_missing_trump = sum(!is.na(Trump_Votes))
  )

# Calculate the mean and variance for votes and percentages
stats_summary <- actual_results %>%
  summarise(
    mean_Harris_Votes = mean(Harris_Votes, na.rm = TRUE),
    var_Harris_Votes = var(Harris_Votes, na.rm = TRUE),
    mean_Trump_Votes = mean(Trump_Votes, na.rm = TRUE),
    var_Trump_Votes = var(Trump_Votes, na.rm = TRUE),
    mean_percent_harris = mean(percent_harris, na.rm = TRUE),
    var_percent_harris = var(percent_harris, na.rm = TRUE),
    mean_percent_trump = mean(percent_trump, na.rm = TRUE),
    var_percent_trump = var(percent_trump, na.rm = TRUE)
  )

# View the missing data summary
print(missing_summary)

# View the statistical summary
print(stats_summary)
```

### Bibliography

- Kaggle. *Polymarket 2024 US Election State Data*. Retrieved from: <https://www.kaggle.com/datasets/pbizil/polymarket-2024-us-election-state-data>  
- FiveThirtyEight. *2024 Presidential Polls*. Retrieved from: <https://projects.fivethirtyeight.com/polls/president-general/2024/national/>  
- CBS News. *2024 Presidential Election Results*. Retrieved from: <https://www.cbsnews.com/elections/2024/president/>