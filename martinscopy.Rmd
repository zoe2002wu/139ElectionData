 
To start analyzing our betting data we will first begin by processing our monthly data such that we can analyze state averages for each month. We will first look at the popularity of the canddiates within each state and refine our visualizations down to states which our betting data suggests are close:

```{r}

library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)


#Access csv files in directory
file_path <- "data/betting_data/polymarket/csv_month/"

file_list <- list.files(path = file_path, pattern = "*.csv", full.names = TRUE)

# Data frames to store results
final_data <- data.frame()

for (file in file_list) {
  state_data <- read_csv(file, show_col_types = FALSE)
  
  # Extract the state abbreviation from the file name
  state_abbrev <- tools::file_path_sans_ext(basename(file)) %>% 
    stringr::str_extract("^[A-Z]{2}")
  
  # Calculate averages for  Trump and Harris
  avg_trump <- mean(state_data$`Donald Trump`, na.rm = TRUE)
  avg_harris <- mean(state_data$`Kamala Harris`, na.rm = TRUE)
  
  # Create a new data structure for average percentages
  state_results <- data.frame(
    candidate = c("Donald Trump", "Kamala Harris"),
    percentage = c(avg_trump, avg_harris),
    state = c(state_abbrev, state_abbrev)
  )
  
  final_data <- bind_rows(final_data, state_results)
}

# Calculate nationwide statistics
nationwide_stats <- final_data %>%
  group_by(candidate) %>%
  summarise(
    nationwide_mean = mean(percentage, na.rm = TRUE),
    nationwide_sd = sd(percentage, na.rm = TRUE)
  )


print(nationwide_stats)

```

First to analyze poularity within each state we make a heat map for each state depicting the division of the state for each candidate:
```{r}
install.packages("sf")
install.packages("maps")
install.packages("tigris")
```
```{r}
# Calculate the blue percentage (Kamala Harris's share of the total percentage)
single_percent <- final_data %>%
  filter(candidate %in% c("Kamala Harris", "Donald Trump")) %>% # Keep only relevant candidates
  pivot_wider(names_from = candidate, values_from = percentage) %>% # Reshape to wide format
  mutate(
    blue_percentage = `Kamala Harris` / (`Kamala Harris` + `Donald Trump`) # Calculate ratio
  ) %>%
  select(state, blue_percentage) # Keep only state and blue_percentage

# Print result
print(single_percent)
```

```{r}
library(sf)
library(dplyr)
library(ggplot2)

# Calculate blue_percentage as a percentage (0 to 100)
single_percent <- final_data %>%
  filter(candidate %in% c("Kamala Harris", "Donald Trump")) %>%
  pivot_wider(names_from = candidate, values_from = percentage) %>%
  mutate(
    blue_percentage = 100 * `Kamala Harris` / (`Kamala Harris` + `Donald Trump`)
  ) %>%
  select(state, blue_percentage)

# Download U.S. state geometries
us_states <- tigris::states(cb = TRUE, year = 2021) %>%
  filter(!STUSPS %in% c("PR", "VI", "GU", "MP", "AS")) %>% # Exclude territories
  select(state = STUSPS, geometry)

# Merge state geometries with single_percent
map_data <- us_states %>%
  left_join(single_percent, by = "state")


# Plot the fixed map
ggplot(map_data) +
  geom_sf(aes(fill = blue_percentage), color = "white", lwd = 0.2) +
  scale_fill_gradient2(
    low = "red", mid = "white", high = "blue",
    midpoint = 50,
    name = "Kamala Harris Preference (%)"
  ) +
  labs(
    title = "U.S. Map of Preferences for Presidential Candidates",
    subtitle = "Based on Average Percentages",
    caption = "Data Source: Polymarket"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank()
  ) +
  coord_sf(crs = "+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +lon_0=-96") # Albers projection

```


